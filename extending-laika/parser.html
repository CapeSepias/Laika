<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">

    <title>Laika</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Customizable and extensible toolkit for transforming lightweight markup languages to various types of output formats, written in Scala" />
    <meta name="keywords" content="scala, text, markup, markdown, restructuredtext, parser, transformer, html, template engine, site generation, open-source" />

    <link href="../css/bootstrap.css" rel="stylesheet">
    <link href="../css/docs.css" rel="stylesheet">

    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

  </head>

  <body data-spy="scroll" data-target=".toc" data-offset="200">


  <div class="container">

    <!-- Docs nav
    ================================================== -->
    <div class="row">
      <div class="span4 toc" >
        
        <ul class="nav nav-list affix">
          <div class="nav-top"><img src="../img/laika-top.png"/></div>
          
          
          <li class="nav-header">Introduction</li>
          <li><a href="../introduction/intro.html">Overview</a></li>
          <li><a href="../introduction/architecture.html">Architecture</a></li>
          <li class="nav-header">Using Laika</li>
          <li><a href="../using-laika/sbt.html">Using the sbt Plugin</a></li>
          <li><a href="../using-laika/embedded.html">Using Laika Embedded</a></li>
          <li><a href="../using-laika/markup.html">Supported Markup</a></li>
          <li><a href="../using-laika/output.html">Supported Output Formats</a></li>
          <li><a href="../using-laika/structure.html">Document Structure</a></li>
          <li><a href="../using-laika/templates.html">Templates</a></li>
          <li class="nav-header">Customizing Laika</li>
          <li><a href="../customizing-laika/customize-rendering.html">Customizing Renderers</a></li>
          <li><a href="../customizing-laika/tree-rewriting.html">Document Tree Rewriting</a></li>
          <li><a href="../customizing-laika/parsing-rendering.html">Separate Parsing and Rendering</a></li>
          <li class="nav-header">Extending Laika</li>
          <li><a href="directive.html">Directives</a></li>
          <li class="active"><a href="#">Parsers</a></li>
          <li><a href="renderer.html">Renderers</a></li>
          <li><a href="extending-rst.html">Extending reStructuredText</a></li>
          
          <li class="nav-header">Project Links</li>
          <li><a href="http://github.com/planet42/Laika">Source Code</a></li>
          <li><a href="../api/laika/api/">API Documentation</a></li>
          <li><a href="http://github.com/planet42/Laika/issues">Issue Tracker</a></li>
          <li><a href="http://planet42.org/">Transformer Web Tool</a></li>
          <li class="follow"><a href="https://twitter.com/_planet42" class="twitter-follow-button" data-show-count="false" data-show-screen-name="false" data-dnt="true">Follow @_planet42</a>
          <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script></li>
          
          <div class="nav-bottom"><img src="../img/laika-bottom.png" border="1"/></div>
        </ul>
        
      </div>
      
      <div class="span8" id="top">

        <div class="page-header">
          <h1>Implementing a Parser</h1>
        </div>
        <p>This document describes the best practices for adding an entirely new parser to the toolkit.
        It is only useful if you either plan to implement a parser for a markup language not (yet)
        supported by Laika, want to replace one of the existing parsers, or are just
        curious about the inner workings of the library. None of the information here is required
        for standard usage of Laika.</p>
        
        <h2 id="factory-contract" class="section">Factory Contract</h2>
        <p>The contract a parser factory has to adhere to is captured in the following
        trait:</p>
        <pre>trait MarkupParser {

  def fileSuffixes: Set[String]

  def blockParsers: Seq[BlockParserBuilder]
  
  def spanParsers: Seq[SpanParserBuilder]

  def extensions: Seq[ExtensionBundle]
  
}</pre>
        <p>These are the four abstract method each parser has to implement.  <br></p>
        <p>The <code>fileSuffixes</code> method should simply return the set of supported file
        suffixes (without the &#39;.&#39;). For Markdown this would be <code>Set(&quot;md&quot;, &quot;markdown&quot;)</code>
        for example. It is not recommended to support generic suffixes like <code>txt</code> as this
        could lead to conflicts with other parsers.</p>
        <p>The <code>blockParsers</code> and <code>spanParsers</code> collections provide the definitions for the
        actual markup parsers. They are based on Laika&#39;s own parser combinator implementation
        that is optimized for parsing of text markup. See the sections below for how to 
        create such a definition.</p>
        <p>The <code>extensions</code> collection allows to add functionality beyond just markup parsing.
        If, for example, the markup parser inserts AST nodes into the final result that
        are not known to the default renderers for HTML, EPUB or PDF, an extension might provide
        additional renderers for these custom nodes. </p>
        <p>See the <a href="../api/laika/bundle/ExtensionBundle.html">ExtensionBundle Scaladoc</a> for an overview of the available
        extension hooks.</p>
        <p>Finally there are two concrete methods that may be overridden if required:</p>
        <pre>def escapedChar: Parser[String] = TextParsers.any.take(1)

def createBlockListParser (parser: Parser[Block]): Parser[Seq[Block]] = 
  (parser &lt;~ opt(blankLines))*</pre>
        <p>The first method controls the parsing of an escape sequence (the character after
        a backslash). The default implementation accepts any character.</p>
        <p>The second controls how a parser for a single block is turned into a parser for
        a sequence of blocks. The default implementation just skips whitespace between
        the blocks and repeats the same parser. The parser passed to this method already
        includes all the block parsers this trait has specified as well as any extensions
        a user might have installed.</p>
        
        <h2 id="text-parsers" class="section">Text Parsers</h2>
        <p>The functionality provided by these parsers is not strictly required for implementing
        parsers for any markup language. But the parsers are convenient helpers as they are more tailored 
        for the special requirements of parsing text markup, which is quite different from parsing programming 
        languages for example. </p>
        <p>In particular for parsing inline markup (like *this* for adding emphasis) Laika&#39;s parsers deviate
        from the standard approach of combinators, which in this case would often mean to build
        a long list of (flat) choices of (often) regex parsers which are all tried on each character.
        The downside of this approach is that this is often quite slow, and not easily extensible, 
        if you want to support new or customized markup for an existing parser without touching the parser
        implementation.</p>
        <p>For typical basic regex parsers there is usually a corresponding option in the <code>TextParsers</code>
        object. You can see the full list of provided parsers in the <a href="../api/laika/parse/core/text/TextParsers$.html">Scaladoc</a>.
        We&#39;ll just show a few examples here:</p>
        <p>Parsing three or more lower-case characters:</p>
        <pre>&quot;[a-z]{3,}&quot;.r              // regex

anyIn(&#39;a&#39; to &#39;z&#39;) min 3    // Laika alternative</pre>
        <p>Parsing any character apart from space or tab:</p>
        <pre>&quot;[^ \t]*&quot;.r               // regex

anyBut(&#39; &#39;,&#39;\t&#39;)          // Laika alternative</pre>
        <p>Note that for the Laika base parsers the default is to parse any number of characters,
        as this is the most common case. To read just one you can write:</p>
        <pre>anyBut(&#39; &#39;,&#39;\t&#39;) take 1</pre>
        <p>The parsers of this trait will be faster than regex parsers in many scenarios, but
        there will be edge cases where it is the other way round. To be really sure it&#39;s best
        to do some benchmarks first. </p>
        
        <h2 id="span-parsers" class="section">Span Parsers</h2>
        <p>Laika parses text markup in two phases: in the first phase it only looks for markup which is
        significant for identifying a block type (like a blockquote, an ordered list, a code block
        or a regular paragraph for example). It then further parses the text of each block to look
        for inline markup, which is what this trait does.</p>
        <p>Like described in the previous section, Laika inline parsers avoid the performance bottleneck
        of trying a long list of choices for each character. Instead it builds a map of available
        span parsers, mapping from the first character to the parser, and then performs a simple
        map lookup for each character. If no parser is mapped to the character it simply continues
        reading. This works for nested structures, too.</p>
        <p>This is captured in the API for creating a parser:</p>
        <pre>SpanParser.forStartChar(&#39;*&#39;).standalone {
  delimitedBy(&quot;*&quot;)
}    </pre>
        <p>The parser above simply parses text between two asterisk. The <code>standalone</code> method means
        that the parser is independent of any parsers in the host language.</p>
        <p>If the parser is allowed to contain nested spans with any of the parsers of the host language
        or any installed extensions, your definition must ask for the recursive parser to be provided
        as you cannot anticipate the extensions a user might have configured:</p>
        <pre>SpanParser.forStartChar(&#39;*&#39;).recursive { recParsers =&gt;
  recParsers.delimitedRecursiveSpans(delimitedBy(&quot;*&quot;))
} </pre>
        <p>Here you simply pass the same text parser from the previous example to the recursive
        parsers provided by Laika which lifts the text parser into a span parser.</p>
        <p>It&#39;s important that parsers do not look for the initial character as this will be consumed by the map lookup already. 
        And they are still allowed to fail, in which case the special character will be treated as
        normal text input.</p>
        
        <h2 id="block-parsers" class="section">Block Parsers</h2>
        <p>The API for creating block parsers is similar to that for span parsers. One difference
        is that the start character is optional, as many types of blocks, like a plain paragraph
        for example, do not have a concrete start character. In those cases you can create the block
        parser like this:</p>
        <pre>BlockParser.withoutStartChar.standalone {
  // your parser impl
}    </pre>
        <p>If the parser allows the nesting of other blocks you can rely on the library to pass
        the recursive parsers for all installed block parsers to your parser definition, similar
        to the span parser mechanism:</p>
        <pre>BlockParser.forStartChar(&#39;*&#39;).recursive { recParsers =&gt;
  // your parser impl
} </pre>
        <p>Laika offers a <code>BlockParsers</code> object with convenience methods for creating
        a typical block parser. This is the signature of the first one:</p>
        <pre>def block (firstLinePrefix: Parser[Any], 
           linePrefix: Parser[Any], 
           nextBlockPrefix: Parser[Any]): Parser[List[String]]</pre>
        <p>It allows to parse a block based on three simple conditions, provided in form of
        the three parser parameters: detecting the first line of a block, any subsequent
        line and finally whether the block continues after a blank line has been seen.
        Often a blank line marks the end of a block, but there are exceptions, like code
        blocks or list items that span multiple paragraphs.</p>
        <p>The following code is an example for a parser for quoted blocks, decorated
        by a <code>&gt;</code> character at the start of each line:</p>
        <pre>BlockParser.forStartChar(&#39;&gt;&#39;).recursive { recParsers =&gt;
  
  val textAfterDeco = TextParsers.ws       // any whitespace
  val decoratedLine = &#39;&gt;&#39; ~ textAfterDeco  // &#39;&gt;&#39; followed by whitespace
  val afterBlankLine = Parsers.failure(&quot;blank line ends block&quot;)
  
  val textBlock = BlockParsers.block(textAfterDeco, decoratedLine, afterBlankLine)
  
  recParsers.recursiveBlocks(textBlock) ^^ (QuotedBlock(_, Nil))
}
</pre>
        <p>This implementation uses the <code>BlockParsers</code> helper. It passes just the whitespace
        parser as the condition for the first line, as the start character has already 
        been consumed. For subsequent lines, the decoration needs to be present, so
        we pass <code>decoratedLine</code> as the condition for them.</p>
        <p>Finally we pass the <code>textBlock</code> parser to the recursive parsers which lift our
        <code>Parser[String]</code> to a <code>Parser[Seq[Block]]</code> and the result of that parser is 
        passed to the <code>QuotedBlock</code> AST node.</p>
        <p>Finally there is a second utility that can be used for indented blocks:</p>
        <pre>def indentedBlock (minIndent: Int = 1,
          linePredicate: =&gt; Parser[Any] = success(()),
          endsOnBlankLine: Boolean = false,
          firstLineIndented: Boolean = false,
          maxIndent: Int = Int.MaxValue): Parser[String]</pre>
        <p>Like the other utility it allows to specify a few predicates. This method
        is not used for parsing Markdown&#39;s indented blocks, though, as Markdown has
        a very special way of treating whitespace.</p>      

      </div>
    </div>

  </div>

</body></html>
